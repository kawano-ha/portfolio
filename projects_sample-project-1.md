# スクレイピング自動化ツール

概要
- 目的: あるECサイトの商品情報を定期的に収集し、価格変動と在庫の監視をするための自動化ツールを作成。
- 期間: 2週間（週10時間程度）
- 役割: 要件定義・実装・テスト・運用スクリプト作成

技術スタック
- 言語: Python
- ライブラリ: BeautifulSoup, requests, pandas
- 実行環境: Linux (cron) / Docker

やったこと（要点）
1. 対象ページの解析とHTMLから必要データ抽出
2. 取得結果をCSVに整形して保存
3. cron で定期実行、ログ出力とエラーハンドリングを実装
4. 軽いリファクタリングで将来の対象サイト追加を容易に

成果・効果
- 手動で行っていたデータ収集が自動化され、工数を週4時間削減
- 収集データを基に価格警告メールを送る仕組みの基礎を提供

学び・改善点
- サイト構造の変更に弱い実装だったため、セレクタの抽出方法を設定ファイル化し保守性を向上させた。
- 大量取得時の負荷対策にリトライ・レート制御を追加。

リンク
- GitHub: https://github.com/your-username/sample-scraper (例)